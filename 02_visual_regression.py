import pandas as pd
import matplotlib.pyplot as plt
import seaborn as sns
import statsmodels.api as sm
import statsmodels.formula.api as smf
import statsmodels.stats.api as sms
from statsmodels.stats.outliers_influence import variance_inflation_factor
import platform, re

#  í•œê¸€ í°íŠ¸ ì„¤ì •
if platform.system() == "Windows":
    plt.rc('font', family='Malgun Gothic')
elif platform.system() == "Darwin":
    plt.rc('font', family='AppleGothic')
else:
    plt.rc('font', family='NanumGothic')
plt.rcParams['axes.unicode_minus'] = False

print(" ë°ì´í„° ë¶ˆëŸ¬ì˜¤ëŠ” ì¤‘...")

# ------------------------------------------------------------
# 1. ê²½ì°°ì²­ ì‚¬ì´ë²„ë²”ì£„ í†µê³„
# ------------------------------------------------------------
crime = pd.read_csv("police_cybercrime.csv", encoding="cp949")
crime = crime.rename(columns={crime.columns[0]: "year", crime.columns[1]: "êµ¬ë¶„"})
crime = crime[crime["êµ¬ë¶„"] == "ë°œìƒê±´ìˆ˜"].copy()
crime["year"] = pd.to_numeric(crime["year"], errors="coerce")
crime["total_crime"] = crime.iloc[:, 2:].sum(axis=1)
print(" ì‚¬ì´ë²„ë²”ì£„ ë¯¸ë¦¬ë³´ê¸°:")
print(crime[["year", "total_crime"]].head())

# ------------------------------------------------------------
# 2. ì‹ ë¢°ì§€ìˆ˜ ë°ì´í„°
# ------------------------------------------------------------
trust = pd.read_csv("trust_index.csv", encoding="utf-8-sig", skiprows=2)
trust = trust.rename(columns={trust.columns[0]: "êµ¬ë¶„"})
trust = trust[trust["êµ¬ë¶„"].astype(str).str.contains("ì „ì²´")].copy()
trust = trust.melt(id_vars=["êµ¬ë¶„"], var_name="year", value_name="trust_index")
trust["year"] = pd.to_numeric(trust["year"], errors="coerce")
trust["trust_index"] = pd.to_numeric(trust["trust_index"], errors="coerce")
trust = trust[["year", "trust_index"]].dropna().sort_values("year")
print("\n ì‹ ë¢°ì§€ìˆ˜ ë¯¸ë¦¬ë³´ê¸°:")
print(trust)

# ------------------------------------------------------------
#  3. ì¸í„°ë„· ì´ìš©ë¥  ë°ì´í„°
# ------------------------------------------------------------
print("\n  ì¸í„°ë„· ì´ìš©ë¥  ë°ì´í„° ì²˜ë¦¬ ì¤‘...")
internet = pd.read_csv("internet_use.csv", encoding="cp949", header=[0, 1])
internet.columns = [f"{a}_{b}".strip("_") if b and b != a else a for a, b in internet.columns]
region_cols = [c for c in internet.columns if "í–‰ì •êµ¬ì—­" in c]
mask = pd.Series([False] * len(internet))
for col in region_cols:
    mask |= internet[col].astype(str).str.contains("ì „ì²´|ì „êµ­|ì†Œê³„", na=False)
internet = internet[mask].copy()
use_cols = [c for c in internet.columns if re.search(r"\d{4}_ì´ìš©$", c)]
print(f" íƒì§€ëœ ì´ìš© ê´€ë ¨ ì—´: {len(use_cols)}ê°œ â†’ {use_cols[:10]}")

internet_use = internet[use_cols].T.reset_index()
internet_use.columns = ["col"] + [f"row_{i}" for i in range(1, len(internet_use.columns))]
internet_use = internet_use[["col", "row_1"]].rename(columns={"row_1": "internet_rate"})
internet_use["year"] = internet_use["col"].str.extract(r"(\d{4})").astype(int)
internet_use["internet_rate"] = pd.to_numeric(internet_use["internet_rate"], errors="coerce")
internet_use = internet_use[["year", "internet_rate"]].dropna().sort_values("year")

past_data = pd.DataFrame({
    "year": [2015, 2016, 2017, 2018, 2019, 2020],
    "internet_rate": [91.5, 92.0, 92.5, 92.7, 92.9, 93.0],
})
internet_use = pd.concat([past_data, internet_use]).drop_duplicates("year").sort_values("year")
print("\n ì¸í„°ë„· ì´ìš©ë¥  ë¯¸ë¦¬ë³´ê¸°:")
print(internet_use)

# ------------------------------------------------------------
#  4. ë°ì´í„° ë³‘í•©
# ------------------------------------------------------------
merged = crime.merge(internet_use, on="year", how="left").merge(trust, on="year", how="left")
merged = merged.dropna(subset=["total_crime", "internet_rate", "trust_index"]).copy()
print("\n ë³‘í•©ëœ ë°ì´í„° ë¯¸ë¦¬ë³´ê¸°:")
print(merged.head())

# ------------------------------------------------------------
# 5. ê¸°ì´ˆë¶„ì„ (ì—°ë„ë³„ ì¶”ì„¸ ê·¸ë˜í”„)
# ------------------------------------------------------------
# ------------------------------------------------------------
# ìˆ˜ì •ëœ ì‹œê°í™” (ì´ì¤‘ yì¶•)
# ------------------------------------------------------------
fig, ax1 = plt.subplots(figsize=(10, 6))

# ì™¼ìª½ yì¶•: ì‚¬ì´ë²„ë²”ì£„ ê±´ìˆ˜
ax1.plot(merged["year"], merged["total_crime"], color="tab:blue", marker="o", label="ì‚¬ì´ë²„ë²”ì£„ ê±´ìˆ˜")
ax1.set_xlabel("ì—°ë„")
ax1.set_ylabel("ì‚¬ì´ë²„ë²”ì£„ ê±´ìˆ˜", color="tab:blue")
ax1.tick_params(axis='y', labelcolor='tab:blue')

# ì˜¤ë¥¸ìª½ yì¶•: ì¸í„°ë„· ì´ìš©ë¥  + ì‹ ë¢°ì§€ìˆ˜
ax2 = ax1.twinx()
ax2.plot(merged["year"], merged["internet_rate"], color="tab:orange", marker="s", label="ì¸í„°ë„· ì´ìš©ë¥ (%)")
ax2.plot(merged["year"], merged["trust_index"], color="tab:green", marker="^", label="ì‹ ë¢°ì§€ìˆ˜")
ax2.set_ylabel("ì´ìš©ë¥  / ì‹ ë¢°ì§€ìˆ˜", color="tab:green")
ax2.tick_params(axis='y', labelcolor='tab:green')

# ë²”ë¡€ í†µí•©
fig.legend(loc="upper left", bbox_to_anchor=(0.1, 0.9))
plt.title("ì—°ë„ë³„ ì‚¬ì´ë²„ë²”ì£„, ì¸í„°ë„· ì´ìš©ë¥ , ì‹ ë¢°ì§€ìˆ˜ ì¶”ì„¸ (2015~2024)")
plt.grid(True)
plt.tight_layout()
plt.show()
# ------------------------------------------------------------
#  6. ìƒê´€ê´€ê³„ ë¶„ì„ (Pearson r)
# ------------------------------------------------------------
print("\n  ë³€ìˆ˜ ê°„ ìƒê´€ê´€ê³„ (Pearson r):")
corr = merged[["total_crime", "internet_rate", "trust_index"]].corr(method="pearson")
print(corr)
sns.heatmap(corr, annot=True, cmap="coolwarm", vmin=-1, vmax=1)
plt.title("ë³€ìˆ˜ ê°„ ìƒê´€ê´€ê³„ íˆíŠ¸ë§µ")
plt.show()

# ------------------------------------------------------------
#    ê¸°ë³¸ íšŒê·€ë¶„ì„ (OLS)
# ------------------------------------------------------------
print("\n  ê¸°ë³¸ íšŒê·€ë¶„ì„ ìˆ˜í–‰ ì¤‘...")
X = sm.add_constant(merged[["internet_rate", "trust_index"]])
y = merged["total_crime"]
model = sm.OLS(y, X).fit()
print(model.summary())

# ------------------------------------------------------------
#     íšŒê·€ ì§„ë‹¨ (ë‹¤ì¤‘ê³µì„ ì„± + ì”ì°¨ì •ê·œì„±)
# ------------------------------------------------------------
print("\nğŸ§  íšŒê·€ ì§„ë‹¨ ê²°ê³¼:")

# VIF
vif_data = pd.DataFrame()
vif_data["Variable"] = X.columns
vif_data["VIF"] = [variance_inflation_factor(X.values, i) for i in range(X.shape[1])]
print("\n[ VIF ê²°ê³¼]")
print(vif_data)

# Jarque-Bera test
jb_test = sms.jarque_bera(model.resid)
print("\n[ Jarque-Bera Test ê²°ê³¼]")
print(f"JB í†µê³„ëŸ‰: {jb_test[0]:.3f}, p-value: {jb_test[1]:.3f}")
if jb_test[1] > 0.05:
    print("â†’ ì”ì°¨ëŠ” ì •ê·œë¶„í¬ë¥¼ ë”°ë¦„ (ëª¨í˜• ì í•©ì„± ì–‘í˜¸)")
else:
    print("â†’ ì”ì°¨ëŠ” ì •ê·œë¶„í¬ ì•„ë‹˜ (ëª¨í˜• ì¬ê²€í†  í•„ìš”)")

# ------------------------------------------------------------
#  9. ì‹œì°¨ íš¨ê³¼ (Lag)
# ------------------------------------------------------------
print("\n   ì‹œì°¨(Lag) íš¨ê³¼ ë¶„ì„ ì¤‘...")
merged["trust_index_lag"] = merged["trust_index"].shift(1)
lagged_df = merged.dropna(subset=["trust_index_lag"])
X_lag = sm.add_constant(lagged_df[["internet_rate", "trust_index_lag"]])
y_lag = lagged_df["total_crime"]
lag_model = sm.OLS(y_lag, X_lag).fit()
print(lag_model.summary())

# ------------------------------------------------------------
# 10. ë¹„ì„ í˜• ê´€ê³„ (Quadratic)
# ------------------------------------------------------------
print("\n  ë¹„ì„ í˜•(ì œê³±í•­) íšŒê·€ë¶„ì„ ìˆ˜í–‰ ì¤‘...")
merged["trust_index_sq"] = merged["trust_index"] ** 2
X_quad = sm.add_constant(merged[["internet_rate", "trust_index", "trust_index_sq"]])
y_quad = merged["total_crime"]
quad_model = sm.OLS(y_quad, X_quad).fit()
print(quad_model.summary())

# ------------------------------------------------------------
print("\n ëª¨ë“  ë¶„ì„ ì™„ë£Œ! ê·¸ë˜í”„ ë° í†µê³„ ê²°ê³¼ë¥¼ í™•ì¸í•˜ì„¸ìš”.")
